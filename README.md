[![Review Assignment Due Date](https://classroom.github.com/assets/deadline-readme-button-22041afd0340ce965d47ae6ef1cefeee28c7c493a6346c4f15d667ab976d596c.svg)](https://classroom.github.com/a/i99LRj_R)
[![Open in Codespaces](https://classroom.github.com/assets/launch-codespace-2972f46106e565e64193e422d61a12cf1da4916b45550586e14ef0a7c637dd04.svg)](https://classroom.github.com/open-in-codespaces?assignment_repo_id=19439885)
# Assignment 5: Health Data Classification

## Objectives

This assignment focuses on applying classification techniques to synthetic health data. You will practice:

1. **Data Loading and Preparation:** Handling basic data loading and preparing data for modeling.
2. **Binary Classification:** Implementing and evaluating a simple classification model (Logistic Regression).
3. **Model Evaluation:** Calculating and interpreting key classification metrics.
4. **Feature Engineering:** Extracting basic time-series features for classification.
5. **Tree-Based Models:** Implementing and comparing Random Forest and XGBoost classifiers.
6. **Handling Categorical Data:** Using One-Hot Encoding.
7. **Handling Imbalanced Data:** Applying the SMOTE technique to address class imbalance.

## Data

A synthetic dataset named `synthetic_health_data.csv` will be provided (or generated by a script). This dataset simulates basic patient records and includes the following columns:

* `patient_id`: Unique identifier for each patient.
* `timestamp`: Timestamp of the measurement/record.
* `age`: Age of the patient (years).
* `systolic_bp`: Systolic blood pressure (mmHg).
* `diastolic_bp`: Diastolic blood pressure (mmHg).
* `glucose_level`: Blood glucose level (mg/dL).
* `bmi`: Body Mass Index.
* `smoker_status`: Categorical variable ('yes', 'no', 'former').
* `heart_rate`: Heart rate (bpm) - *Used in Part 2*.
* `disease_outcome`: Binary target variable (1 for disease present, 0 for no disease). This target is intentionally imbalanced.

## Assignment Structure

This assignment is divided into three parts, each corresponding to a Jupyter Notebook:

1. **`part1_introduction.ipynb`**: Focuses on loading data, basic exploration, training a Logistic Regression model, and evaluating its performance.
2. **`part2_feature_engineering.ipynb`**: Explores basic time-series feature extraction (using `heart_rate`), training Random Forest and XGBoost models.
3. **`part3_data_preparation.ipynb`**: Deals with handling categorical features (One-Hot Encoding) and addressing class imbalance using SMOTE.

## Simplified Tasks

### Part 0: Data Collection

1. Run `generate_data.py` to generate the `synthetic_health_data.csv` dataset.

### Part 1: Introduction to Classification & Evaluation (`part1_introduction.ipynb`)

1. **Load Data:** Load the `synthetic_health_data.csv` file into a pandas DataFrame.
2. **Prepare Data:** Select relevant features and the target. Split the data into training and testing sets. Handle any missing values.
3. **Train Model:** Train a Logistic Regression model on the training data.
4. **Evaluate Model:** Calculate accuracy, precision, recall, F1 score, AUC, and confusion matrix.
5. **Save Results:** Save the metrics to `results/results_part1.txt`.
6. **Interpret Results:** Implement a function `interpret_results(metrics)` that analyzes the model performance on imbalanced data. The function should return a dictionary with keys 'best_metric', 'worst_metric', and 'imbalance_impact_score' (a custom score from 0-1 indicating how much the class imbalance affected results). Additionally, write your manual interpretation of these results in a file called `RESULTS.md`.

### Part 2: Time Series Features & Tree-Based Models (`part2_feature_engineering.ipynb`)

1. **Extract Features:** Calculate rolling mean and standard deviation for heart rate.
2. **Prepare Data:** Select features including the new rolling features and the target. Split into train/test sets.
3. **Train Models:** Train Random Forest and XGBoost models.
4. **Compare Models:** Calculate and compare AUC scores for both models.
5. **Save Results:** Save the AUC scores to `results/results_part2.txt`.

### Part 3: Practical Data Preparation (`part3_data_preparation.ipynb`)

1. **Encode Categorical Features:** Use One-Hot Encoding for the `smoker_status` column to transform the categorical variable into numerical features.
2. **Prepare Data:** Select features (including the one-hot encoded ones) and the target. Split into train/test sets.
3. **Apply SMOTE:** Oversample the minority class in the training data.
4. **Retrain and Evaluate:** Train a Logistic Regression model on the balanced data and evaluate on the original test set.
5. **Save Results:** Save the evaluation metrics to `results/results_part3.txt`.
6. **Compare Results:** Implement a function `compare_models(part1_metrics, part3_metrics)` that calculates the percentage improvement for each metric between the imbalanced model (Part 1) and the balanced model (Part 3). The function should return a dictionary with metric names as keys and improvement percentages as values. Additionally, write your manual comparison and analysis in the `RESULTS.md` file.

## Submission

Submit your completed notebooks, the `results/` directory containing your output files, and your `RESULTS.md` file with your manual interpretations and analysis.
