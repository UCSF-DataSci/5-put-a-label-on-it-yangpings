{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-07T22:46:12.319718Z",
     "start_time": "2025-05-07T22:46:12.311651Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T22:45:51.676472Z",
     "start_time": "2025-05-07T22:45:51.669473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Load the synthetic health data from a CSV file.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the CSV file\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame containing the data\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # Load the CSV file using pandas\n",
    "    path = file_path\n",
    "    df = pd.read_csv(\n",
    "            file_path,\n",
    "            parse_dates=[\"timestamp\"],   # parses the column to datetime dtype\n",
    "            infer_datetime_format=True)\n",
    "    return df"
   ],
   "id": "3e56444e337ab6c6",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T22:59:44.914302Z",
     "start_time": "2025-05-07T22:59:44.900306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def encode_categorical_features(df, column_to_encode='smoker_status'):\n",
    "    \"\"\"\n",
    "    Encode a categorical column using OneHotEncoder.\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "        column_to_encode: Name of the categorical column to encode\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with the categorical column replaced by one-hot encoded columns\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # 1. Extract the categorical column\n",
    "    # 2. Apply OneHotEncoder\n",
    "    # 3. Create new column names\n",
    "    # 4. Replace the original categorical column with the encoded columns\n",
    "    X_cat = df[[column_to_encode]]\n",
    "\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, dtype=int)\n",
    "    X_ohe = ohe.fit_transform(X_cat)\n",
    "\n",
    "    new_cols = [f\"{column_to_encode}_{cat}\" for cat in ohe.categories_[0]]\n",
    "\n",
    "    df_encoded = pd.DataFrame(X_ohe, columns=new_cols, index=df.index)\n",
    "    df_out = pd.concat([df.drop(columns=[column_to_encode]), df_encoded], axis=1)\n",
    "\n",
    "    return df_out"
   ],
   "id": "e105c992c895b390",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T23:12:47.214430Z",
     "start_time": "2025-05-07T23:12:47.207515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_data_part3(df, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Prepare data with categorical encoding.\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "        test_size: Proportion of data for testing\n",
    "        random_state: Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # 1. Encode categorical features using the encode_categorical_features function\n",
    "    # 2. Select relevant features (including the one-hot encoded ones) and the target\n",
    "    # 3. Split data into training and testing sets\n",
    "    # 4. Handle missing values\n",
    "    df_enc = encode_categorical_features(df, column_to_encode=\"smoker_status\")\n",
    "\n",
    "    target_col = \"disease_outcome\"\n",
    "    y = df_enc[target_col]\n",
    "    X = df_enc.drop(columns=[target_col]).copy()\n",
    "\n",
    "    # --- NEW: make every column numeric ---------------------------------\n",
    "    for col in X.select_dtypes(include=\"datetime64[ns]\").columns:\n",
    "        # Option A -- keep the information (nanoseconds since 1970-01-01)\n",
    "        X[col] = X[col].view(\"int64\")\n",
    "        # Option B -- if you donâ€™t need it, just drop:\n",
    "        # X = X.drop(columns=[col])\n",
    "    # --------------------------------------------------------------------\n",
    "\n",
    "    split_idx = int(len(X) * (1 - test_size))\n",
    "    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    X_train = pd.DataFrame(\n",
    "        imputer.fit_transform(X_train),\n",
    "        columns=X_train.columns,\n",
    "        index=X_train.index\n",
    "    )\n",
    "    X_test = pd.DataFrame(\n",
    "        imputer.transform(X_test),\n",
    "        columns=X_test.columns,\n",
    "        index=X_test.index\n",
    "    )\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ],
   "id": "9701b27f8eef2f64",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T22:51:21.848570Z",
     "start_time": "2025-05-07T22:51:21.843648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def apply_smote(X_train, y_train, random_state=42):\n",
    "    \"\"\"\n",
    "    Apply SMOTE to oversample the minority class.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Training features\n",
    "        y_train: Training target\n",
    "        random_state: Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        Resampled X_train and y_train with balanced classes\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    sm = SMOTE(random_state=random_state)\n",
    "    X_res_arr, y_res_arr = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Convert back to DataFrame/Series to preserve column names and index\n",
    "    X_res = pd.DataFrame(X_res_arr, columns=X_train.columns, index=None)\n",
    "    y_res = pd.Series(y_res_arr, name=y_train.name, index=None)\n",
    "\n",
    "    return X_res, y_res"
   ],
   "id": "fbd7957b31ab4321",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T22:53:52.539048Z",
     "start_time": "2025-05-07T22:53:52.528101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_logistic_regression(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Train a logistic regression model.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Training features\n",
    "        y_train: Training target\n",
    "        \n",
    "    Returns:\n",
    "        Trained logistic regression model\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # Initialize and train a LogisticRegression model\n",
    "    clf = LogisticRegression(\n",
    "        penalty=\"l2\",\n",
    "        solver=\"liblinear\",      # good for small/medium-sized data\n",
    "        max_iter=1000,\n",
    "        class_weight=None        # set to 'balanced' if classes are still skewed\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf\n",
    "\n",
    "def calculate_evaluation_metrics(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Calculate classification evaluation metrics.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        X_test: Test features\n",
    "        y_test: Test target\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing accuracy, precision, recall, f1, auc, and confusion_matrix\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # 1. Generate predictions\n",
    "    # 2. Calculate metrics: accuracy, precision, recall, f1, auc\n",
    "    # 3. Create confusion matrix\n",
    "    # 4. Return metrics in a dictionary\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = getattr(model, \"predict_proba\", None)\n",
    "    y_score = y_prob(X_test)[:, 1] if y_prob is not None else y_pred\n",
    "\n",
    "    acc  = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_test, y_pred, zero_division=0)\n",
    "    auc  = roc_auc_score(y_test, y_score)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1\": f1,\n",
    "        \"auc\": auc,\n",
    "        \"confusion_matrix\": cm,\n",
    "    }"
   ],
   "id": "d3834286be9f5584",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T22:58:28.698171Z",
     "start_time": "2025-05-07T22:58:28.692953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# YOUR CODE HERE\n",
    "# 1. Create 'results' directory if it doesn't exist\n",
    "# 2. Format metrics as strings\n",
    "# 3. Write metrics to 'results/results_part3.txt'\n",
    "def save_to_file(metrics):\n",
    "    results_dir = \"results\"\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    outfile = os.path.join(results_dir, \"results_part3.txt\")\n",
    "    with open(outfile, \"w\") as f:\n",
    "        for k, v in metrics.items():\n",
    "            if isinstance(v, (float, np.floating)):\n",
    "                f.write(f\"{k}: {v:.4f}\\n\")\n",
    "            elif k == \"confusion_matrix\":\n",
    "                # Flatten matrix for compact storage (TN FP FN TP)\n",
    "                cm_str = \" \".join(map(str, v.ravel()))\n",
    "                f.write(f\"{k}: {cm_str}\\n\")\n",
    "            else:  # integers or anything else\n",
    "                f.write(f\"{k}: {v}\\n\")"
   ],
   "id": "4a4f4025669dd923",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T23:27:28.093746Z",
     "start_time": "2025-05-07T23:27:28.081885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compare_models(part1_metrics, part3_metrics):\n",
    "    \"\"\"\n",
    "    Calculate percentage improvement between models trained on imbalanced vs. balanced data.\n",
    "    \n",
    "    Args:\n",
    "        part1_metrics: Dictionary containing evaluation metrics from Part 1 (imbalanced)\n",
    "        part3_metrics: Dictionary containing evaluation metrics from Part 3 (balanced)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with metric names as keys and improvement percentages as values\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # 1. Calculate percentage improvement for each metric\n",
    "    # 2. Handle metrics where higher is better (most metrics) and where lower is better\n",
    "    # 3. Return a dictionary with metric names and improvement percentages\n",
    "    \n",
    "    # Placeholder return - replace with your implementation\n",
    "    lower_is_better = {\"log_loss\"}\n",
    "    improvements = {}\n",
    "\n",
    "    for metric, p1_value in part1_metrics.items():\n",
    "        # Skip arrays / lists / matrices\n",
    "        if np.asarray(p1_value).ndim != 0:\n",
    "            continue\n",
    "\n",
    "        p3_value = part3_metrics.get(metric)\n",
    "        if p3_value is None or np.asarray(p3_value).ndim != 0:\n",
    "            continue\n",
    "\n",
    "        if p1_value == 0:\n",
    "            improvements[metric] = np.nan\n",
    "            continue\n",
    "\n",
    "        direction = -1 if metric in lower_is_better else 1\n",
    "        pct_change = direction * (p3_value - p1_value) / abs(p1_value) * 100\n",
    "        improvements[metric] = pct_change\n",
    "\n",
    "    return improvements"
   ],
   "id": "5f9a6dbb57fc582d",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def read_metrics_txt(path):\n",
    "    \"\"\"\n",
    "    Parse a metrics text file that looks like:\n",
    "        accuracy: 0.9195\n",
    "        ...\n",
    "        confusion_matrix:\n",
    "        1302 22\n",
    "        96   46\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict   # {'accuracy': 0.9195, ..., 'confusion_matrix': np.ndarray}\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    with open(path, \"r\") as f:\n",
    "        lines = [ln.strip() for ln in f if ln.strip()]\n",
    "\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "        if line.startswith(\"confusion_matrix\"):\n",
    "            # next two lines contain the 2Ã—2 matrix\n",
    "            row1 = list(map(int, lines[i + 1].split()))\n",
    "            row2 = list(map(int, lines[i + 2].split()))\n",
    "            metrics[\"confusion_matrix\"] = np.array([row1, row2])\n",
    "            i += 3\n",
    "        else:\n",
    "            k, v = line.split(\":\", 1)\n",
    "            metrics[k.strip()] = float(v)\n",
    "            i += 1\n",
    "    return metrics"
   ],
   "id": "d7d7e42f223458fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T23:27:31.625367Z",
     "start_time": "2025-05-07T23:27:31.587241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Load data\n",
    "    data_file = 'data/synthetic_health_data.csv'\n",
    "    df = load_data(data_file)\n",
    "\n",
    "    # 2. Prepare data with categorical encoding\n",
    "    X_train, X_test, y_train, y_test = prepare_data_part3(df)\n",
    "\n",
    "    # 3. Apply SMOTE to balance the training data\n",
    "    X_train_resampled, y_train_resampled = apply_smote(X_train, y_train)\n",
    "\n",
    "    # 4. Train model on resampled data\n",
    "    model = train_logistic_regression(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    # 5. Evaluate on original test set\n",
    "    metrics = calculate_evaluation_metrics(model, X_test, y_test)\n",
    "\n",
    "    # 6. Print metrics\n",
    "    for metric, value in metrics.items():\n",
    "        if metric != 'confusion_matrix':\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "    # 7. Save results\n",
    "    save_to_file(metrics)\n",
    "\n",
    "    # 8. Load Part 1 results for comparison\n",
    "    import json\n",
    "\n",
    "    try:\n",
    "        part1_metrics = read_metrics_txt(\"results/results_part1.txt\")\n",
    "\n",
    "        # 9. Compare models\n",
    "        comparison = compare_models(part1_metrics, metrics)\n",
    "        print(\"\\nModel Comparison (improvement percentages):\")\n",
    "        for metric, improvement in comparison.items():\n",
    "            print(f\"{metric}: {improvement:.2f}%\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Part 1 results not found. Run part1_introduction.ipynb first.\")"
   ],
   "id": "52735ec8ed598f42",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.0682\n",
      "precision: 0.0682\n",
      "recall: 1.0000\n",
      "f1: 0.1277\n",
      "auc: 0.4925\n",
      "\n",
      "Model Comparison (improvement percentages):\n",
      "accuracy: -92.58%\n",
      "precision: -89.92%\n",
      "recall: 208.74%\n",
      "f1: -70.85%\n",
      "auc: -44.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ericy\\AppData\\Local\\Temp\\ipykernel_3700\\3215795810.py:14: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df = pd.read_csv(\n",
      "C:\\Users\\ericy\\AppData\\Local\\Temp\\ipykernel_3700\\859627075.py:27: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  X[col] = X[col].view(\"int64\")\n",
      "C:\\Users\\ericy\\PycharmProjects\\DATASCI 223\\.venv\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 35
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
